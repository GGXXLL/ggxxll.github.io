[{"content":"概述 https://zhuanlan.zhihu.com/p/98135840\n链接 文档 在线体验 数据库引擎 Lazy\n会将最近一次查询的表保存在内存中, 过期时间为expiration_time_in_seconds. 仅适用于*Log表引擎. 如果表的数量较多, 数据量小, 且访问间隔长, 建议使用Lazy引擎数据库. Atomic\n不指定引擎时, 默认使用Atomic. 支持无阻塞删除和重命名表. 默认会生成UUID, 不建议指定UUID 不改变uuid和迁移表数据的话, 执行rename table可以立即生效 DROP/DETACH TABLE不会真正的删除表, 只是标记被删除了. 如果同步模式设置为SYNC, 在等待已有的查询/插入操作结束之后, 表会被立即删除. 使用表引擎ReplicatedMergeTree, 不建议指定path和replica name ReplicatedReplacingMergeTree('/clickhouse/tables/{shard}/{database}/{table}', '{replica}') Mysql\n远程映射Mysql的库表. 在clickhouse执行的查询等, 会被引擎转换, 发送到Mysql服务中. 不能执行 RENAME, CREATE TABLE, ALTER 简单 WHERE 条款如 =, !=, \u0026gt;, \u0026gt;=, \u0026lt;, \u0026lt;= 当前在MySQL服务器上执行。其余的条件和 LIMIT 只有在对MySQL的查询完成后，才会在ClickHouse中执行采样约束。 删除DROP和卸载DETACH 表，不会删除mysql中的表，且允许通过ATTACH再装载回来 不支持的Mysql的数据类型会转换成String, 所有类型都支持Nullable MaterializeMySQL\n使用MySQL中存在的所有表以及这些表中的所有数据创建ClickHouse数据库（即库级别的数据同步）。ClickHouse服务器用作MySQL副本。它读取binlog并执行DDL和DML查询。默认表引擎设置为ReplacingMergeTree\n使用表引擎 ReplacingMergeTree 时, 会添加虚拟列 _sign 和 _version\n_version — Transaction counter. Type [UInt64]\n_sign — Deletion mark. Type [Int8]. Possible values:\n1 — Row is not deleted, -1 — Row is deleted. MySQL DDL查询将转换为相应的ClickHouse DDL查询（ALTER，CREATE，DROP，RENAME）。如果ClickHouse无法解析某些DDL查询，则该查询将被忽略。\n不支持 INSERT, DELETE 和 UPDATE操作. 复制时都视为INSERT操作, 会在数据上使用_sign标记.\nINSERT, 1 DELETE, -1 UPDATE, 1或-1 执行SELECT查询时\n不指定_version, 默认使用FINAL, 即MAX(_version) 不指定_sign, 默认会限制查询条件WHERE _sign=1 注意事项:\n_sign=-1的数据是逻辑删除 不支持update/delete 复制过程很容易崩溃 禁止手动操作数据库和表 通过设置optimize_on_insert, 启用或禁用在插入之前进行数据转换，就像合并是在此块上完成的（根据表引擎）一样。 不支持的Mysql数据类型会异常Unhandled data type并停止复制， 都支持Nullable PostgreSQL 远程链接PostgreSQL. 支持查询, 插入等操作. 支持修改表结构 (注意使用缓存时的情况: DETACH 和ATTCH可刷新缓存). 数据类型中仅INTEGER支持Nullable 表引擎 文档 MergeTree Kakfa，Mysql 创建数据库 1 CREATE DATABASE [IF NOT EXISTS] db_name [ON CLUSTER cluster] [ENGINE = engine(...)] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster] ( name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [COMMENT expr1] [TTL expr1], name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [COMMENT expr1] [TTL expr2], ... INDEX index_name1 expr1 TYPE type1(...) GRANULARITY value1, INDEX index_name2 expr2 TYPE type2(...) GRANULARITY value2 ) ENGINE = MergeTree() -- 指定数据排序使用字段，默认等同主键 ORDER BY (expr1[, expr2,...]) -- 指定数据分区使用的字段 [PARTITION BY (expr1[, expr2,...])] -- 指定主键 [PRIMARY KEY (expr1[, expr2,...])] -- 指定采样数据使用的字段，启用数据采样时，不会对所有数据执行查询，而只对特定部分数据（样本）执行查询 [SAMPLE BY (expr1[, expr2,...])] [TTL expr [DELETE|TO DISK \u0026#39;xxx\u0026#39;|TO VOLUME \u0026#39;xxx\u0026#39; [, ...] ] [WHERE conditions] [GROUP BY key_expr [SET v1 = aggr_func(v1) [, v2 = aggr_func(v2) ...]] ] ] [SETTINGS name=value, ...] 字典 字典是一个映射 (键 -\u0026gt; 属性）, 是方便各种类型的参考清单。\nClickHouse支持一些特殊函数配合字典在查询中使用。 将字典与函数结合使用比将 JOIN 操作与引用表结合使用更简单、更有效。\n内置字典：处理地理数据库 外部字典：自定义字典 特殊查询 1 2 3 4 5 6 7 8 9 10 11 -- 计算pv值\u0026gt;20的记录条数 select sum(pv\u0026gt;20) from test_all; select count(*) from test_all where pv\u0026gt;20; -- 计算pv\u0026gt;20的记录条数占比：0.5 select avg(pv\u0026gt;20) from test_all; -- 计算pv在1,2，20这几个值中的记录条数的占比 select avg(pv in (1,2,2,20)) from test_all; -- Date系列类型， 插入时可以混合时间戳和字符串插入 INSERT INTO dt Values (1546300800, 1), (\u0026#39;2019-01-01\u0026#39;, 2); 数据类型 UUID FixedString Enum LowCardinality(T), 把其它数据类型转变为字典编码类型。如果该字段的值去重个数小于1W，性能优于普通类型。反之，性能下降。 通常， 一个字符串类型的Enum类型， 建议设置为LowCardinality， 更灵活和高效 Array(T\u0026hellip;) AggregateFunction， 适用于表引擎 AggregatingMergeTree Nested 嵌套字段， 不支持表引擎 MergeTree Tuple Nullable Domains： IPV4， IPV6 Geo： experimental feature Point ： 坐标，Tuple（x float64, y float64） Ring： Array(Point) Polygon： Array(Ring) MultiPolygon：Array(Polygon) Map(key,value) experimental feature SimpleAggregateFunction 性能优于 AggregateFunction， 适用于表引擎 AggregatingMergeTree 注意事项 使用 Nullable 几乎总是对性能产生负面影响，在设计数据库时请记住这一点, 最好设置default值。 删除表的时候， 会先在元数据标记被删除，exists、select、insert等会立即生效（表不存在）， 但是create table创建表等操作会抛异常（表存在）。 稍等几分钟，再新建表即可。 删除表数据，应当操作本地表，操作分布式Distributed表会报错。 ReplacingMergeTree表引擎， 完全相同的数据会直接去重， 数据是在后台不确定的时间去合并去重的。不建议使用OPTIMIZE发起合并， 使用 FINAL 关键字进行查询，可以得到主键相同的、最新被插入的数据。 那些有相同分区表达式值PARTITION BY的数据片段才会合并。这意味着 你不应该用太精细的分区方案（超过一千个分区）。否则，会因为文件系统中的文件数量过多和需要打开的文件描述符过多，导致 SELECT 查询效率不佳。可以根据group by语句来分析如何分区。绝对不能使用带有主键性质的字段做分区（比如唯一id）， 最好选择一个重复率高的字段（比如 日期， 渠道等）。 Alter语句DROP, MODIFY 时， 该字段不能是主键，会报错 使用 1 2 3 4 5 6 7 8 9 10 create table test on cluster cluster1 ( date Date, id UInt32 default 0 comment \u0026#39;123\u0026#39;, name String default \u0026#39;\u0026#39;, pv UInt32 default 0 ) ENGINE = ReplicatedReplacingMergeTree(\u0026#39;/clickhouse/tables/{shard}/{database}/{table}\u0026#39;, \u0026#39;{replica}\u0026#39;) PARTITION BY date ORDER BY (date,id); 1 2 3 4 5 6 7 8 create table test_all on cluster cluster1 ( date Date, id UInt32 default 0 comment \u0026#39;123\u0026#39;, name String default \u0026#39;\u0026#39;, pv UInt32 default 0 ) engine = Distributed(\u0026#39;cluster1\u0026#39;, \u0026#39;wangzhuan\u0026#39;, \u0026#39;test\u0026#39;, sipHash64(date)); 1 2 3 4 -- 结果是一条数据 insert into test_all (date, id, name, pv) VALUES (\u0026#39;2021-05-20\u0026#39;,1,\u0026#39;a\u0026#39;,10), (\u0026#39;2021-05-20\u0026#39;,1,\u0026#39;a\u0026#39;,10); 1 2 3 4 5 6 7 8 9 10 11 12 13 -- 结果是两条数据 insert into test_all (date, id, name, pv) VALUES (\u0026#39;2021-05-20\u0026#39;, 1, \u0026#39;a\u0026#39;, 10) , (\u0026#39;2021-05-20\u0026#39;, 1, \u0026#39;a\u0026#39;, 20); -- 结果是两条数据 30被20覆盖了， insert into test_all (date, id, name, pv) VALUES (\u0026#39;2021-05-20\u0026#39;, 1, \u0026#39;a\u0026#39;, 30) , (\u0026#39;2021-05-20\u0026#39;, 1, \u0026#39;a\u0026#39;, 20); -- 当然， 经过后台的数据合并之后， 应该是只剩1条数据 pv=30的 1 2 3 4 5 6 7 select * from test_all; select * from test_all final; select sum(pv) from test_all; select sum(pv) from test_all final; 1 2 3 alter table test on cluster cluster1 delete where 1; alter table test on cluster cluster1 delete where date=\u0026#39;2021-05-20\u0026#39;; 1 2 3 4 5 6 7 8 9 10 11 12 -- 仅当分区被使用到（PARTITION BY的字段的值超过一个），system.parts表里才会有数据 SELECT partition, name, active FROM system.parts WHERE table = \u0026#39;test\u0026#39;; SELECT table,count(*) FROM system.parts group by table order by count(*) desc; 1 2 drop table test on cluster cluster1; drop table test_all on cluster cluster1; ","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/clickhouse%E5%88%9D%E4%BD%93%E9%AA%8C/","title":"Clickhouse初体验"},{"content":"环境 工具：docker，docker-compose 需求描述 在本地搭建业务中可能使用的服务，方便本地进行测试。\n配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 version: \u0026#34;3\u0026#34; services: zookeeper: container_name: zookeeper image: \u0026#39;bitnami/zookeeper:latest\u0026#39; ports: - \u0026#39;2181:2181\u0026#39; environment: - ALLOW_ANONYMOUS_LOGIN=yes kafka: container_name: kafka image: \u0026#39;bitnami/kafka:latest\u0026#39; ports: - \u0026#39;9092:9092\u0026#39; environment: - KAFKA_BROKER_ID=1 - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092 - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://127.0.0.1:9092 - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181 - ALLOW_PLAINTEXT_LISTENER=yes depends_on: - zookeeper volumes: - \u0026#39;kafka:/bitnami/kafka\u0026#39; redis: container_name: redis image: \u0026#39;redis:latest\u0026#39; ports: - \u0026#39;6379:6379\u0026#39; volumes: - \u0026#39;redis:/usr/local/etc/redis\u0026#39; mysql: container_name: mysql image: \u0026#39;mysql:latest\u0026#39; ports: - \u0026#39;3306:3306\u0026#39; environment: MYSQL_ALLOW_EMPTY_PASSWORD: \u0026#39;yes\u0026#39; MYSQL_DATABASE: app volumes: - \u0026#39;mysql:/var/lib/mysql\u0026#39; mongo: container_name: mongo image: \u0026#39;mongo:latest\u0026#39; ports: - \u0026#39;27017:27017\u0026#39; volumes: - \u0026#39;mongo:/data/db\u0026#39; etcd: container_name: etcd image: \u0026#39;quay.io/coreos/etcd:latest\u0026#39; ports: - \u0026#39;2379:2379\u0026#39; - \u0026#39;2380:2380\u0026#39; volumes: - \u0026#39;etcd:/etcd-data\u0026#39; command: - /usr/local/bin/etcd - --data-dir=/etcd-data - --name=node1 - --initial-advertise-peer-urls=http://192.168.82.116:2380 - --listen-peer-urls=http://0.0.0.0:2380 - --advertise-client-urls=http://192.168.82.116:2379 - --listen-client-urls=http://0.0.0.0:2379 - --initial-cluster - node1=http://192.168.82.116:2380 es: container_name: es image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0 environment: - discovery.type=single-node ulimits: memlock: soft: -1 hard: -1 volumes: - es:/usr/share/elasticsearch/data ports: - \u0026#39;9200:9200\u0026#39; volumes: redis: {} mysql: {} kafka: {} es: {} mongo: {} etcd: {} ","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/docker%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","title":"docker测试环境搭建"},{"content":"环境 系统: windows 语言: golang 框架: gin Bug描述 在如下代码中, ctx := c和ctx := context.Background()传递到cli.Set中是没有问题的.\n使用ctx := c.Request.Context()时, 会打印出错误: context canceled.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/go-redis/redis/v8\u0026#34; ) func main() { cli := redis.NewClient(\u0026amp;redis.Options{ Addr: \u0026#34;127.0.0.1:6379\u0026#34;, }) r := gin.Default() r.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context) { //ctx := c //ctx := context.Background() ctx := c.Request.Context() go func() { if err := cli.Set(ctx, \u0026#34;hello\u0026#34;, 1, 0).Err(); err != nil { fmt.Println(err) } }() c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;pong\u0026#34;, }) }) r.Run() // listen and serve on 0.0.0.0:8080 } 分析 gin的Request对象来自*http.Request, handlerFunc被调用完成之后, context就被cancel了\n在ctx := c.Request.Context()打断点, 可以找到如下代码:\n1 2 3 4 5 6 func{ ... serverHandler{c.server}.ServeHTTP(w, w.req) w.cancelCtx() ... } 其他 使用gin+opentracing时, 不能使用 作为上下文传递, 要使用c.Request.Context(), 而不是gin.Context. 需要在goroutine中传递ctx, 应该拿出span新建一个ctx 1 2 3 4 func NewTracingContextWithParentContext(ctx context.Context) context.Context { span := opentracing.SpanFromContext(ctx) return opentracing.ContextWithSpan(context.Background(), span) } ginhttp中封装好了相应的中间件, 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 func Middleware(tr opentracing.Tracer, options ...MWOption) gin.HandlerFunc { opts := mwOptions{ opNameFunc: func(r *http.Request) string { return \u0026#34;HTTP \u0026#34; + r.Method }, spanObserver: func(span opentracing.Span, r *http.Request) {}, urlTagFunc: func(u *url.URL) string { return u.String() }, } for _, opt := range options { opt(\u0026amp;opts) } return func(c *gin.Context) { carrier := opentracing.HTTPHeadersCarrier(c.Request.Header) ctx, _ := tr.Extract(opentracing.HTTPHeaders, carrier) op := opts.opNameFunc(c.Request) sp := tr.StartSpan(op, ext.RPCServerOption(ctx)) ext.HTTPMethod.Set(sp, c.Request.Method) ext.HTTPUrl.Set(sp, opts.urlTagFunc(c.Request.URL)) opts.spanObserver(sp, c.Request) // set component name, use \u0026#34;net/http\u0026#34; if caller does not specify componentName := opts.componentName if componentName == \u0026#34;\u0026#34; { componentName = defaultComponentName } ext.Component.Set(sp, componentName) c.Request = c.Request.WithContext( opentracing.ContextWithSpan(c.Request.Context(), sp)) c.Next() ext.HTTPStatusCode.Set(sp, uint16(c.Writer.Status())) sp.Finish() } } ","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/gin-opentracing%E7%9A%84%E4%BD%BF%E7%94%A8/","title":"gin+opentracing的使用"},{"content":"使用Kibana + Filebeat + Nginx 进行日志监控，Nginx的error日志的时区提前了8个小时，解决方案如下：\n原博： https://www.colabug.com/2018/0425/2780769/\n步骤一 将 /usr/share/filebeat/module/nginx/error/ingest/pipeline.json 里面的\n1 2 3 4 5 6 7 \u0026#34;date\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;nginx.error.time\u0026#34;, \u0026#34;target_field\u0026#34;: \u0026#34;@timestamp\u0026#34;, \u0026#34;formats\u0026#34;: [\u0026#34;yyyy/MM/dd H:m:s\u0026#34;], {\u0026lt; if .convert_timezone \u0026gt;}\u0026#34;timezone\u0026#34;: \u0026#34;{{ beat.timezone }}\u0026#34;,{\u0026lt; end \u0026gt;} \u0026#34;ignore_failure\u0026#34;: true } 改为：\n1 2 3 4 5 6 7 \u0026#34;date\u0026#34;: { \u0026#34;field\u0026#34;: \u0026#34;nginx.error.time\u0026#34;, \u0026#34;target_field\u0026#34;: \u0026#34;@timestamp\u0026#34;, \u0026#34;formats\u0026#34;: [\u0026#34;yyyy/MM/dd H:m:s\u0026#34;], \u0026#34;timezone\u0026#34; : \u0026#34;Asia/Shanghai\u0026#34;, \u0026#34;ignore_failure\u0026#34;: true } 步骤二 1 2 3 4 5 6 7 8 9 删除旧的pipeline: curl -XDELETE \u0026#34;http://localhost:9200/_ingest/pipeline/filebeat-6.7.0-nginx-error-pipeline\u0026#34; # 重新设置 filebeat setup -e # 查看是否生效 curl -XGET \u0026#34;http://localhost:9200/_ingest/pipeline/filebeat-6.7.0-nginx-error-pipeline\u0026#34; 注意： 一般来说索引格式固定，修改版本号（6.7.0）为自己的安装版本\n","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/kibana-filebeat-nginx%E7%9A%84error%E6%97%A5%E5%BF%97%E6%97%B6%E5%8C%BA%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","title":"Kibana+Filebeat+Nginx的error日志时区问题解决方案"},{"content":"原贴: https://www.cnblogs.com/winkey4986/p/6433704.html\n\u0026ndash;数据库中单个表的大小（不包含索引）\n1 select pg_size_pretty(pg_relation_size(\u0026#39;表名\u0026#39;)); \u0026ndash;查出所有表（包含索引）并排序\n1 2 3 4 SELECT table_schema || \u0026#39;.\u0026#39; || table_name AS table_full_name, pg_size_pretty(pg_total_relation_size(\u0026#39;\u0026#34;\u0026#39; || table_schema || \u0026#39;\u0026#34;.\u0026#34;\u0026#39; || table_name || \u0026#39;\u0026#34;\u0026#39;)) AS size FROM information_schema.tables ORDER BY pg_total_relation_size(\u0026#39;\u0026#34;\u0026#39; || table_schema || \u0026#39;\u0026#34;.\u0026#34;\u0026#39; || table_name || \u0026#39;\u0026#34;\u0026#39;) DESC limit 20 \u0026ndash;查出表大小按大小排序并分离data与index\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 SELECT table_name, pg_size_pretty(table_size) AS table_size, pg_size_pretty(indexes_size) AS indexes_size, pg_size_pretty(total_size) AS total_size FROM ( SELECT table_name, pg_table_size(table_name) AS table_size, pg_indexes_size(table_name) AS indexes_size, pg_total_relation_size(table_name) AS total_size FROM ( SELECT (\u0026#39;\u0026#34;\u0026#39; || table_schema || \u0026#39;\u0026#34;.\u0026#34;\u0026#39; || table_name || \u0026#39;\u0026#34;\u0026#39;) AS table_name FROM information_schema.tables ) AS all_tables ORDER BY total_size DESC ) AS pretty_sizes ","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/postgresql%E6%9F%A5%E8%AF%A2%E8%A1%A8%E7%9A%84%E5%A4%A7%E5%B0%8F/","title":"Postgresql查询表的大小"},{"content":"环境 系统: windows 语言: golang IDE: goland 安装 Protoc 下载protoc-xxx-win64.zip, 并解压到安装位置(如: d:/protoc)即可 添加环境变量d:/protoc/bin到PATH中 使用protoc --version验证是否安装成功 配置 Golang 环境 下载第三方protobuf库, 并解压到d:/protoc/include, 如: googleapis gogo/protobuf go install google.golang.org/protobuf/cmd/protoc-gen-go 安装goland插件 Protocol Buffer Editor, 按照README在配置中添加d:/protoc/include和自己实现的库的路径(目前好像是每个项目使用时都需要配置一下), 完成之后就有自动提示了（可能需要重启IDE） 使用 命令: protoc -I=. --go_out=. example.proto -I用于指定imports path, 第三方库统一放到d:/protoc/include的话是不需要指定的 官方文档 包括protobuf语法和其他语言的使用教程点击\n","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/protoc%E4%BD%BF%E7%94%A8/","title":"Protoc使用"},{"content":"某日突然发现Sublime Text3（3.2.2）插件OmniMarkupPreviewer打开页面出现404错误\n1 2 3 4 5 6 7 Error: 404 Not Found Sorry, the requested URL \u0026#39;http://127.0.0.1:51004/view/26\u0026#39; caused an error: \u0026#39;buffer_id(26) is not valid (closed or unsupported file format)\u0026#39; **NOTE:** If you run multiple instances of Sublime Text, you may want to adjust the `server_port` option in order to get this plugin work again. 查看Console窗口出现如下错误：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 OmniMarkupPreviewer: [ERROR] Exception occured while rendering using MarkdownRenderer Traceback (most recent call last): File \u0026#34;%AppData%\\Roaming\\Sublime Text 3\\Packages\\OmniMarkupPreviewer\\OmniMarkupLib\\RendererManager.py\u0026#34;, line 266, in render_text rendered_text = renderer.render(text, filename=filename) File \u0026#34;%AppData%\\Roaming\\Sublime Text 3\\Packages\\OmniMarkupPreviewer\\OmniMarkupLib\\Renderers/MarkdownRenderer.py\u0026#34;, line 48, in render extensions=self.extensions) File \u0026#34;%AppData%\\Roaming\\SUBLIM~1\\Packages\\PYTHON~3\\st3\\markdown\\core.py\u0026#34;, line 390, in markdown md = Markdown(**kwargs) File \u0026#34;%AppData%\\Roaming\\SUBLIM~1\\Packages\\PYTHON~3\\st3\\markdown\\core.py\u0026#34;, line 100, in __init__ configs=kwargs.get(\u0026#39;extension_configs\u0026#39;, {})) File \u0026#34;%AppData%\\Roaming\\SUBLIM~1\\Packages\\PYTHON~3\\st3\\markdown\\core.py\u0026#34;, line 126, in registerExtensions ext = self.build_extension(ext, configs.get(ext, {})) File \u0026#34;%AppData%\\Roaming\\SUBLIM~1\\Packages\\PYTHON~3\\st3\\markdown\\core.py\u0026#34;, line 166, in build_extension module = importlib.import_module(ext_name) File \u0026#34;./python3.3/importlib/__init__.py\u0026#34;, line 90, in import_module File \u0026#34;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026#34;, line 1584, in _gcd_import File \u0026#34;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026#34;, line 1565, in _find_and_load File \u0026#34;\u0026lt;frozen importlib._bootstrap\u0026gt;\u0026#34;, line 1529, in _find_and_load_unlocked ImportError: No module named \u0026#39;xxx\u0026#39; 原因 OmniMarkupPreviewer插件使用python-markdown@3.2.2\nSublime Text3使用python-markdown@3.1.1\n当sys.path中的路径下有相同包名时，import会优先导入路径靠前的包\n所以Sublime Text3按照启动顺序加载sys.path后，会优先使用python-markdown@3.1.1，出现导包错误\n解决方案 本人是windows系统，使用%AppData%\\Sublime Text 3\\Packages\\OmniMarkupPreviewer\\OmniMarkupLib\\Renderers\\libs\\markdown文件夹覆盖%AppData%\\Sublime Text 3\\Packages\\python-markdown\\st3\\markdown\n然后重启Sublime Text3即可\n","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/sublimetext3-omnimarkuppreviewer%E5%87%BA%E7%8E%B0404%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","title":"SublimeText3+OmniMarkupPreviewer出现404问题解决方案"},{"content":"supervisor安装使用, 并配置服务崩溃邮件报警\n环境 系统: Centos7, python3\n安装依赖: 1 yum install -y supervisor sendmail mailx \u0026amp;\u0026amp; pip3 install superlance 配置邮件: vim /etc/mail.rc, 然后添加如下内容: 1 2 3 4 5 6 7 8 9 # 发件人邮箱 set from=xxx@xxx.com # smtp服务 set smtp=smtps://smtp.xxx.com:465 # 用户名 set smtp-auth-user=xxx@xxx.com # 密码 set smtp-auth-password=xxx set ssl-verify=ignore 测试邮件: echo 'this is test'| /usr/bin/mail -s 'xxxxx' xxx@xx.com 配置项目: 编辑项目的配置文件, vim /etc/supervisord.d/xxx.ini\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 项目相关配置 [program:projectName] # 设置命令在指定的目录内执行 directory=projectPath # 这里为您要管理的项目的启动命令 command=projectRunCmd # 以哪个用户来运行该进程 user=root # supervisor 启动时自动该应用 autostart=true # 进程退出后自动重启进程 autorestart=true # 进程持续运行多久才认为是启动成功 startsecs=2 # 重试次数 startretries=3 # stderr 日志输出位置 stderr_logfile=path/stderr.log # stdout 日志输出位置 stdout_logfile=path/stdout.log 1 2 3 4 5 6 7 8 # 报警邮件相关配置 [eventlistener:crashmail] command=crashmail -p senddemo -s \u0026#34;echo \u0026#39;projectName crashed!!\u0026#39;| /usr/bin/mail -s \u0026#39;projectName\u0026#39; xxx@xx.com,xxx@xx.com\u0026#34; events=PROCESS_STATE_EXITED ## stderr 日志输出位置 stderr_logfile=path/crashmail/stderr.log ## stdout 日志输出位置 stdout_logfile=path/crashmail/stdout.log 相关命令: 1 2 3 4 5 6 7 8 9 supervisord -c /etc/supervisord.conf # 启动supervisor, 然后才可可以使用supervisorctl supervisorctl stop program_name # 停止某一个进程，program_name 为 [program:name] 里的 name supervisorctl start program_name # 启动某个进程 supervisorctl restart program_name # 重启某个进程 supervisorctl stop groupworker: # 结束所有属于名为 groupworker 这个分组的进程 (start，restart 同理) supervisorctl stop groupworker:name1 # 结束 groupworker:name1 这个进程 (start，restart 同理) supervisorctl stop all # 停止全部进程，注：start、restartUnlinking stale socket /tmp/supervisor.sock supervisorctl reload # 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程 supervisorctl update # 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启 ","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/supervisor%E4%BD%BF%E7%94%A8/","title":"Supervisor使用"},{"content":"简介 core 是由大佬Reasno创建的一个golang开源库.。这个库的定位是一个服务容器，负责管理和协调符合 Twelve-Factor的网络应用程序。\n目前这个库的结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 core ├── clihttp ├── config ├── container ├── contract ├── cronopts ├── di ├── doc ├── dtx ├── events ├── internal ├── key ├── leader ├── logging ├── observability ├── otes ├── otetcd ├── otgorm ├── otkafka ├── otmongo ├── otredis ├── ots3 ├── queue ├── srvhttp ├── text └── unierr ","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AEcore/","title":"开源项目core"},{"content":"题一 问题1： 会输出什么？为什么？ 问题2： 应该如何修改？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import \u0026#34;fmt\u0026#34; func main() { cache := Cache{} fmt.Println(cache.Get(\u0026#34;foo\u0026#34;)) cache.Set(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;) fmt.Println(cache.Get(\u0026#34;foo\u0026#34;)) } type Cache struct { data map[string]interface{} } func (c Cache) Get(s string) (interface{},bool) { v, ok := c.data[s] return v, ok } func (c Cache) Set(s string, v interface{}) { c.data[s] = v } 题二 问题1：会输出什么？为什么？ 问题2：应该如何修改？ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package main import \u0026#34;fmt\u0026#34; func main() { cache := Cache{} cache.Add(1) fmt.Println(cache.List()) } type Cache struct { data []interface{} } func (c Cache) Add(s interface{}) { c.data = append(c.data, s) } func (c Cache) List() []interface{} { return c.data } 题三 问题1：为什么题一需要初始化data，题二不需要? 问题2：实现这个Cache还需要什么补充的吗? 题一解 问题1： Get 返回 nil, false Set 会报空指针错误 问题2： Cache 需要初始化 data 题二解 问题1： 输出空数组 问题2： 修改 func (c Cache) Add 为 func (c *Cache) Add 题三解 问题1：因为 map 是引用传递，数组是值传递 问题2：需要添加锁 sync.Mutex ，并将 Cache 的方法改为指针调用 ","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/%E4%BD%BF%E7%94%A8-map-%E8%AE%BE%E8%AE%A1%E7%BC%93%E5%AD%98/","title":"使用 map 设计缓存"},{"content":"环境 golang 问题 在k8s中部署多个节点服务时，CDN的Range回源经常失败。\n原因：每个节点生成渠道包的时间（Modify-Time）不同，导致CDN回源时认为文件变动了，自动停止回源。\n解决：使用http.ServeContent, 手动传递\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // serveFile // 将newApkPath地址下的文件返回给请求方。 // 注意：曾经这里是使用ctx.File(调用了Go的http.ServeFile)方法返回文件， // 但是这样做在集群部署的情况下存在问题。集群每个节点文件生成的时间存在差异， // 而go标准库中的实现是根据文件的最后修改时间判断文件是否发生了变动。 // 大文件下载时CDN会采用分片回源（Range Header）， 每个分片获取到的最后修改时间不一致，会判定为下载失败！ // 这里改成http.ServeContent实现后，强制将修改时间置为0值，Go的标准库会忽略最后修改时间检测，在集群-多节点环境下也能正常分片下载了。 func serveFile(ctx *gin.Context, newApkPath string) error { _, apkName := filepath.Split(newApkPath) ctx.Header(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/octet-stream\u0026#34;) ctx.Header(\u0026#34;Content-Disposition\u0026#34;, \u0026#34;attachment; filename=\u0026#34;+apkName) ctx.Header(\u0026#34;Content-Transfer-Encoding\u0026#34;, \u0026#34;binary\u0026#34;) f, err := os.OpenFile(newApkPath, os.O_RDONLY, os.ModePerm) if err != nil { return err } defer f.Close() /* 最后修改时间，强制0值，跳过检查 */ http.ServeContent(ctx.Writer, ctx.Request, apkName, time.Time{}, f) return nil } ","date":"2022-08-24T00:00:00Z","permalink":"https://ggxxll.github.io/p/%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BDbug/","title":"文件下载Bug"}]